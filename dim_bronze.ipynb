{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b732ab20-64b5-4ba2-9084-09e638488159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "import pyspark.sql.functions as F\n",
    "catalog_name = 'ecommerce'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a17da97-fbae-4a8f-bc2a-133f9fb9ffee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f8359f6-bb37-4caa-858a-2f78319c1130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "brand_schema = StructType([\n",
    "    StructField('brand_code', StringType(),False),\n",
    "    StructField('brand_name', StringType(), True),\n",
    "    StructField('category_code', StringType(), True)\n",
    "])\n",
    "\n",
    "raw_path = '/Volumes/ecommerce/source_data/raw/ecomm-raw-data/brands/brands.csv'\n",
    "df = spark.read.csv(raw_path, header=True, schema=brand_schema)\n",
    "\n",
    "# metadata \n",
    "df = df.withColumn('ingested_at',F.current_timestamp())\\\n",
    "    .withColumn('_source_file',F.col(\"_metadata.file_path\"))\\\n",
    "\n",
    "\n",
    "df.write.format('delta')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('overwriteSchema','true')\\\n",
    "    .saveAsTable(f'{catalog_name}.bronze.brz_brands')\n",
    "\n",
    "\n",
    "display(df.limit(5))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a878a23-6615-405e-a055-25a91c9f4587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Customers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94e3c7c6-b459-463b-a80d-c9c823612099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "customers_schema = StructType([\n",
    "    StructField('customer_id', StringType(),False),\n",
    "    StructField('phone', FloatType(), True),\n",
    "    StructField('country_code', StringType(), True),\n",
    "    StructField('country', StringType(), True),\n",
    "    StructField('state', StringType(), True)]\n",
    ")\n",
    "\n",
    "raw_path = '/Volumes/ecommerce/source_data/raw/ecomm-raw-data/customers/customers.csv'\n",
    "# metadata \n",
    "df = spark.read.csv(raw_path, header=True, schema=customers_schema)\\\n",
    "    .withColumn('ingested_at',F.current_timestamp())\\\n",
    "    .withColumn('_source_file',F.col(\"_metadata.file_path\"))\n",
    "\n",
    "\n",
    "df.write.format('delta')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('overwriteSchema','true')\\\n",
    "    .saveAsTable(f'{catalog_name}.bronze.brz_customers')\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d67622-ef06-4e38-85c7-6adea28917f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09f24782-0a05-477c-af7b-dc8bdc2a6ce8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "category_schema = StructType(\n",
    "    [StructField('category_code', StringType(),False),\n",
    "    StructField('category_name', StringType(), False)]\n",
    ")\n",
    "\n",
    "raw_path = '/Volumes/ecommerce/source_data/raw/ecomm-raw-data/category/category.csv'\n",
    "# metadata \n",
    "df = spark.read.csv(raw_path, header=True, schema=category_schema)\\\n",
    "    .withColumn(\"_ingested_at\", F.current_timestamp()) \\\n",
    "    .withColumn(\"_source_file\", F.col(\"_metadata.file_path\"))\n",
    "\n",
    "df.write.format('delta')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('overwriteSchema','true')\\\n",
    "    .saveAsTable(f'{catalog_name}.bronze.brz_category')\n",
    "\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afc3a68d-4451-4476-b007-87b8fdc9bcb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "945a0e6f-bf8d-4baa-add0-07d9f08bbb19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "\n",
    "products_schema=StructType(\n",
    "   [\n",
    "    StructField('product_id', LongType(),False),\n",
    "    StructField('sku', StringType(), True),\n",
    "    StructField('category_code', StringType(), True),\n",
    "    StructField('brand_code', StringType(), True),\n",
    "    StructField('color', StringType(), True),\n",
    "    StructField('size', StringType(), True),\n",
    "    StructField('material', StringType(), True),\n",
    "    StructField('weight_grams', StringType(), True),\n",
    "    StructField('length_cm', StringType(), True),\n",
    "    StructField('width_cm', FloatType(), True),\n",
    "    StructField('height_cm', FloatType(), True),\n",
    "    StructField('rating_count', FloatType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "raw_path = '/Volumes/ecommerce/source_data/raw/ecomm-raw-data/products/products.csv'\n",
    "# metadata \n",
    "df = spark.read.csv(raw_path, header=True, schema=products_schema)\\\n",
    "    .withColumn(\"_ingested_at\", F.current_timestamp()) \\\n",
    "    .withColumn(\"_source_file\", F.col(\"_metadata.file_path\"))\n",
    "\n",
    "\n",
    "df.write.format('delta')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('overwriteSchema','true')\\\n",
    "    .saveAsTable(f'{catalog_name}.bronze.brz_products')\n",
    "    \n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e20318a1-955c-4f0c-a7b6-f5aa6f5550c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "\n",
    "date_schema = StructType([\n",
    "    StructField('date', StringType(),False),\n",
    "    StructField('year', IntegerType(), True),\n",
    "    StructField('day_name', StringType(), True),\n",
    "    StructField('quarter', IntegerType(), True),\n",
    "    StructField('week_of_year', IntegerType(), True)\n",
    "])\n",
    "\n",
    "raw_path = '/Volumes/ecommerce/source_data/raw/ecomm-raw-data/date/date.csv'\n",
    "\n",
    "# metadata \n",
    "df = spark.read.csv(raw_path, header=True, schema=date_schema)\\\n",
    "    .withColumn(\"_ingested_at\", F.current_timestamp()) \\\n",
    "    .withColumn(\"_source_file\", F.col(\"_metadata.file_path\"))\n",
    "\n",
    "\n",
    "df.write.format('delta')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('overwriteSchema','true')\\\n",
    "    .saveAsTable(f'{catalog_name}.bronze.brz_date')\n",
    "    \n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a70f422e-cfae-4793-9931-4b01852efc58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5984508106359533,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "dim_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
